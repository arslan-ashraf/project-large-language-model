{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nvidia-ml-py3"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rymcvqjd3_DU",
        "outputId": "e551eb5d-30cd-4de6-ff1c-bb8c3b146f0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.10/dist-packages (7.352.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-62Qb78-HGz",
        "outputId": "09e50830-4fa9-46cc-85d2-f0047db416ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jun  7 04:39:26 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pynvml import *\n",
        "\n",
        "def print_gpu_utilization():\n",
        "    nvmlInit()\n",
        "    handle = nvmlDeviceGetHandleByIndex(0)\n",
        "    info = nvmlDeviceGetMemoryInfo(handle)\n",
        "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")"
      ],
      "metadata": {
        "id": "rxHpbQDQ356X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def activations_memory(num_layers, seq_len, batch_size, hidden_dim, num_heads, bits_per_param=4):\n",
        "    \"Amount of RAM (in GB) required to store intermediate activations for a Transformer Encoder\"\n",
        "    memory_in_bytes = num_layers * bits_per_param * batch_size * seq_len * hidden_dim * (\n",
        "        16 + 2/bits_per_param + 2*num_heads*seq_len/hidden_dim + num_heads*seq_len/(bits_per_param*hidden_dim))\n",
        "    return \"RAM required in GB: \" + str(round(memory_in_bytes / 10**9, 2))"
      ],
      "metadata": {
        "id": "HLOR5gZT_eaS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activations_memory(12, 1024, 4, 768, 12, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Xq1TS4-m_hwb",
        "outputId": "f32dcd8d-d812-43bb-eb4d-1ebfad088584"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RAM required in GB: 7.93'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zrUqEa7SqnK7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/Colab Notebooks/Projects/Project - Large Language Model\"\n",
        "\n",
        "model_path = base_path + \"/transformer_decoder.py\"\n",
        "data_path = base_path + \"/python-tokenized-data\""
      ],
      "metadata": {
        "id": "DnXtun8K0sEQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import model code"
      ],
      "metadata": {
        "id": "YcOI1prh1FEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "execfile(model_path)"
      ],
      "metadata": {
        "id": "ujPiqyQ6xlFZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define model config"
      ],
      "metadata": {
        "id": "yVenJGA11IH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "star_coder_tokenizer_vocab_size = 49152\n",
        "transformer_decoder_dim = 768\n",
        "\n",
        "config = {\n",
        "    \"num_heads\": 12,\n",
        "    \"is_masked\": True,\n",
        "    \"embedding_dim\": transformer_decoder_dim,\n",
        "    \"hidden_dim\": transformer_decoder_dim,\n",
        "    \"first_layer_size\": 4 * transformer_decoder_dim,\n",
        "    \"droptout_rate\": 0.2,\n",
        "    \"vocab_size\": star_coder_tokenizer_vocab_size,\n",
        "    \"max_seq_length\": 1024,\n",
        "    \"num_decoder_blocks\": 12\n",
        "}"
      ],
      "metadata": {
        "id": "acsPsbbBrcF-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#     resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"\")\n",
        "#     tf.config.experimental_connect_to_cluster(resolver)\n",
        "#     tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "#     strategy = tf.distribute.TPUStrategy(resolver)\n",
        "# except ValueError:\n",
        "#     print(\"TPU not found\")\n",
        "\n",
        "# with strategy.scope():\n",
        "#     model = TransformerDecoderModel(config)"
      ],
      "metadata": {
        "id": "rml8vvO2utQW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize and compile model"
      ],
      "metadata": {
        "id": "OiDuanb31Rud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerDecoderModel(config)\n",
        "\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)"
      ],
      "metadata": {
        "id": "lID_BpGE-oA_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define training callbacks"
      ],
      "metadata": {
        "id": "7YQLBhjK1Xbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = base_path + \"/transformer_decoder_model.keras\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,\n",
        "                                                               monitor=\"loss\",\n",
        "                                                               save_best_only=True)\n",
        "\n",
        "date_and_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
        "tensorboard_logs_dir = base_path + \"/tensorboard_logs/\" + date_and_time\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_logs_dir,\n",
        "                                                      histogram_freq=1)"
      ],
      "metadata": {
        "id": "bSq3uim4zz3C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training"
      ],
      "metadata": {
        "id": "dm3ZkEmv612Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_files = os.listdir(data_path)\n",
        "\n",
        "for data_file in data_files:\n",
        "    data_file_subdir = data_path + \"/\" + data_file\n",
        "    x_y_files_in_dir = os.listdir(data_file_subdir)\n",
        "    num_x_y_files = len(x_y_files_in_dir) // 2\n",
        "    for i in range(1, num_x_y_files + 1):\n",
        "        x_file_path = \"x_\" + data_file + \"_part_\" + str(i)\n",
        "        y_file_path = \"y_\" + data_file + \"_part_\" + str(i)\n",
        "\n",
        "        x_data_path = data_file_subdir + \"/\" + x_file_path + \".csv\"\n",
        "        y_data_path = data_file_subdir + \"/\" + y_file_path + \".csv\"\n",
        "\n",
        "        x_train = pd.read_csv(x_data_path, dtype=np.int32)\n",
        "        y_train = pd.read_csv(y_data_path, dtype=np.int32)\n",
        "\n",
        "        model.fit(x_train,\n",
        "                  y_train,\n",
        "                  epochs=1,\n",
        "                  batch_size=4,\n",
        "                  callbacks=[model_checkpoint_callback, tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2u96NDYtoIc",
        "outputId": "195edfe4-99c3-4266-dfea-9578ff0699c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2726/6250 [============>.................] - ETA: 1:31:32 - loss: 6.3363"
          ]
        }
      ]
    }
  ]
}